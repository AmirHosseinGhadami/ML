{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importing_data():\n",
    "    import pandas as pd\n",
    "    n=True\n",
    "    while n:\n",
    "        try:\n",
    "            direction=input(\"Enter Direction...\\n\")\n",
    "            df=pd.read_csv(str(direction))\n",
    "            print(\"Great...You're Amazing...\\n\\n\")\n",
    "            n=False\n",
    "        except:\n",
    "            print('Wrong Direction...Try Again')   \n",
    "            \n",
    "            \n",
    "    return df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scalling():\n",
    "    import pandas as pd\n",
    "    \n",
    "    #Importing data using importing_data function\n",
    "    df = importing_data()\n",
    "    \n",
    "    print('which feature scalling method do you want...?')\n",
    "    print('A == Normalization ')\n",
    "    print('B == standardization\\n\\n')\n",
    "    \n",
    "    y = df.iloc[:,-1]\n",
    "    df = df.iloc[:,:-1]\n",
    "    feature_scalling = input(' Enter (A) or (B)')\n",
    "    while True:\n",
    "          if (feature_scalling.upper() == 'A') or (feature_scalling.upper()=='B'):\n",
    "              break\n",
    "          else:\n",
    "              print(' Enter (A) or (B)')\n",
    "              feature_scalling = input(' Enter (A) or (B)\\n')\n",
    "            \n",
    "     \n",
    "    \n",
    "    if  feature_scalling =='A':\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        n = Normalizer()\n",
    "        dfn = n.fit_transform(df)\n",
    "        dfn = pd.DataFrame(dfn ,index=df.index , columns = df.columns)\n",
    "        dfn[\"y\"] =y \n",
    "        return dfn\n",
    "    \n",
    "    else:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        s = StandardScaler()\n",
    "        dfs = s.fit_transform(df)\n",
    "        dfs = pd.DataFrame(dfs ,index=df.index , columns = df.columns)\n",
    "        dfs['y'] = y\n",
    "        return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_data():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    global x_train,x_test,y_train,y_test\n",
    "    \n",
    "    #import data with importing_data function\n",
    "    df = feature_scalling()\n",
    "    \n",
    "    \n",
    "    while (True):\n",
    "        try:\n",
    "            train_size = int(input('What Percentage (Train Data)\\n'))\n",
    "            print(\"Perfect....\")\n",
    "            break\n",
    "        except:\n",
    "            print(\"Try Again\")\n",
    "    \n",
    "    test_size = 100-train_size\n",
    "    test_size = test_size/100\n",
    "    \n",
    "    X  = df.iloc[:,:-1].values\n",
    "    Y  = df.iloc[:,-1].values\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y , test_size=test_size ,random_state=0)\n",
    "    \n",
    "    test_train_data = {}\n",
    "    test_train_data['X_Test']=x_test\n",
    "    test_train_data['X_train']=x_train\n",
    "    test_train_data['Y_Test']=y_test\n",
    "    test_train_data['Y_train']=y_train\n",
    "    \n",
    "    return test_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import splitted Data with spliting_data function ( 80 percent )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Direction...\n",
      "data1.csv\n",
      "Great...You're Amazing...\n",
      "\n",
      "\n",
      "which feature scalling method do you want...?\n",
      "A == Normalization \n",
      "B == standardization\n",
      "\n",
      "\n",
      " Enter (A) or (B)a\n"
     ]
    }
   ],
   "source": [
    "train_test_data_1 = splitting_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifire_80 = LogisticRegression()\n",
    "classifire_80.fit(train_test_data_1[\"X_train\"] , train_test_data_1['Y_train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = classifire_80.predict(train_test_data_1['X_Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.concatenate((y_pred_1.reshape(len(y_pred_1),1), train_test_data_1['Y_Test'].reshape(len(train_test_data_1['Y_Test']),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_pred_1 ,train_test_data_1['Y_Test'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_80 = accuracy_score(y_pred_1 ,train_test_data_1['Y_Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import splitted Data with spliting_data function ( 75 percent )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data_2 = splitting_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling data \n",
    "classifire_75 = LogisticRegression().fit(train_test_data_2['X_train'] ,train_test_data_2['Y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = classifire_75.predict(train_test_data_2['X_Test'])\n",
    "print(np.concatenate((y_pred_2.reshape(len(y_pred_2),1)  ,train_test_data_2['Y_Test'].reshape(len(train_test_data_2['Y_Test']),1)) ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_75 = confusion_matrix(y_pred_2 ,train_test_data_2[\"Y_Test\"])\n",
    "ac_75 = accuracy_score(y_pred_2 ,train_test_data_2[\"Y_Test\"])\n",
    "print(cm_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bar = [ac_80*100 ,ac_75*100]\n",
    "y = ['Accuracy 80' ,'Accuracy 75']\n",
    "\n",
    "plt.bar(y,bar,color=['yellow','green'], width=0.5,edgecolor='red',linewidth=3,tick_label=[\"80 Percent\",'75 Percent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_test_data_1['X_train'][:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(start= x.min()-1 , stop = x[:,0].max()+1 ,step = 0.01)\n",
    "b = np.arange(start= x[:,1].min()-1 , stop = x[:,1].max()+1 ,step = 0.01)\n",
    "\n",
    "xx,yy = np.meshgrid(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = (np.array([xx.ravel() ,yy.ravel()]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifire_80.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
